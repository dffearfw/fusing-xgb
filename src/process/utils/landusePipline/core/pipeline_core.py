# pipeline_core.py
from functools import wraps
from pathlib import Path
from typing import Callable, Dict, Any, List, Optional
import pandas as pd
import logging
import inspect
from dataclasses import dataclass
from contextlib import contextmanager


@dataclass
class PipelineContext:
    """Pipelineæ‰§è¡Œä¸Šä¸‹æ–‡"""
    input_file: str
    output_dir: Path
    step_data: Dict[str, Any] = None
    metadata: Dict[str, Any] = None

    def __post_init__(self):
        self.step_data = {}
        self.metadata = {}
        self.output_dir = Path(self.output_dir)
        self.output_dir.mkdir(exist_ok=True)


class PipelineStep:
    """Pipelineæ­¥éª¤è£…é¥°å™¨"""
    _registry = {}

    def __init__(self, name: str, version: str = "v1"):
        self.name = name
        self.version = version

    def __call__(self, func: Callable) -> Callable:
        @wraps(func)
        def wrapper(ctx: PipelineContext, *args, **kwargs):
            step_key = f"{self.name}_{self.version}"

            # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
            input_file = ctx.step_data.get('previous_output', ctx.input_file)
            if not Path(input_file).exists():
                raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")

            logging.info(f"ğŸ¯ æ‰§è¡Œæ­¥éª¤: {step_key}")

            # æ‰§è¡Œæ­¥éª¤å‡½æ•°
            result = func(ctx, input_file, *args, **kwargs)

            # ä¿å­˜æ­¥éª¤ç»“æœ
            ctx.step_data[step_key] = {
                'input': input_file,
                'output': result,
                'timestamp': pd.Timestamp.now().isoformat()
            }
            ctx.step_data['previous_output'] = result

            logging.info(f"âœ… æ­¥éª¤å®Œæˆ: {step_key} -> {result}")
            return result

        # æ³¨å†Œæ­¥éª¤
        self._registry[f"{self.name}_{self.version}"] = wrapper
        return wrapper

    @classmethod
    def get_step(cls, name: str, version: str = "v1"):
        return cls._registry.get(f"{name}_{version}")


class Pipeline:
    """ç²¾å·§çš„Pipelineæ‰§è¡Œå™¨"""

    def __init__(self, name: str = "LandUsePipeline"):
        self.name = name
        self.steps: List[Dict] = []
        self.logger = logging.getLogger(name)

    def add_step(self, step_name: str, step_func: Callable, **kwargs):
        """æ·»åŠ å¤„ç†æ­¥éª¤"""
        self.steps.append({
            'name': step_name,
            'func': step_func,
            'kwargs': kwargs
        })
        return self  # æ”¯æŒé“¾å¼è°ƒç”¨

    def execute(self, input_file: str, output_dir: str = None) -> str:
        """æ‰§è¡ŒPipeline"""
        if output_dir is None:
            output_dir = Path(input_file).parent / "pipeline_output"

        ctx = PipelineContext(input_file, output_dir)

        self.logger.info(f"ğŸš€ å¯åŠ¨Pipeline: {self.name}")
        self.logger.info(f"è¾“å…¥: {input_file}")
        self.logger.info(f"æ­¥éª¤æ•°: {len(self.steps)}")

        try:
            for i, step in enumerate(self.steps, 1):
                self.logger.info(f"\nğŸ“¦ æ­¥éª¤ {i}/{len(self.steps)}: {step['name']}")
                step['func'](ctx, **step['kwargs'])

            final_output = ctx.step_data['previous_output']
            self.logger.info(f"\nğŸ‰ Pipelineå®Œæˆ: {final_output}")

            # ä¿å­˜æ‰§è¡Œæ‘˜è¦
            self._save_execution_summary(ctx)

            return final_output

        except Exception as e:
            self.logger.error(f"âŒ Pipelineå¤±è´¥: {e}")
            raise

    def _save_execution_summary(self, ctx: PipelineContext):
        """ä¿å­˜æ‰§è¡Œæ‘˜è¦"""
        summary = {
            'pipeline_name': self.name,
            'execution_time': pd.Timestamp.now().isoformat(),
            'input_file': ctx.input_file,
            'output_dir': str(ctx.output_dir),
            'steps': ctx.step_data
        }

        summary_file = ctx.output_dir / "execution_summary.json"
        import json
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

        self.logger.info(f"ğŸ“Š æ‰§è¡Œæ‘˜è¦: {summary_file}")