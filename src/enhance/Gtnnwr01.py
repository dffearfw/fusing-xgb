import os
import sys
import numpy as np
import pandas as pd
sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))
from gnnwr.datasets import init_dataset_split
from gnnwr.models import GTNNWR
from visualizer import plot_gtnnwr_results, plot_multiple_models_results


data = pd.read_excel('lu_onehot.xlsx')
data["id"] = np.arange(len(data))
# æ·»åŠ æ··åˆåˆ†å‰²ç­–ç•¥
data['station_id'] = data['X'].astype(str) + '_' + data['Y'].astype(str)

# --- ç¬¬1æ­¥ï¼šç«™ç‚¹åˆ’åˆ† (ä¿è¯ç©ºé—´å®Œå…¨ç‹¬ç«‹) ---
unique_stations = data['station_id'].unique()

np.random.shuffle(unique_stations)

test_stations = unique_stations[:int(len(unique_stations) * 0.1)]
train_val_stations = unique_stations[int(len(unique_stations) * 0.1):]

# --- ç¬¬2æ­¥ï¼šä¸ºè®­ç»ƒ/éªŒè¯é›†å‡†å¤‡æ•°æ® ---
train_val_df = data[data['station_id'].isin(train_val_stations)].copy()
train_val_df_sorted = train_val_df.sort_values(by=['year', 'month', 'doy'])

# --- ç¬¬3æ­¥ï¼šæ—¶é—´åˆ’åˆ† (ä¿è¯éªŒè¯é›†çš„æ—¶é—´å¤–æ¨èƒ½åŠ›) ---
valid_sample_count = int(len(train_val_df_sorted) * 0.15)
val_data = train_val_df_sorted.iloc[:valid_sample_count].copy() # æœ€æ—©çš„æ•°æ®
train_data = train_val_df_sorted.iloc[valid_sample_count:].copy() # æœ€æ™šçš„æ•°æ®

# --- ç¬¬4æ­¥ï¼šä¸ºæµ‹è¯•é›†å‡†å¤‡æ•°æ® (ğŸ”¥ æœ€ç»ˆä¿®å¤ï¼šä½¿ç”¨ä¸éªŒè¯é›†ç›¸åŒçš„æ—¶é—´çª—å£) ---
test_df = data[data['station_id'].isin(test_stations)].copy()
test_df_sorted = test_df.sort_values(by=['year', 'month', 'doy'])

# ğŸ”¥ è·å–éªŒè¯é›†çš„æ—¶é—´èŒƒå›´
val_start_time = val_data['year'].min()
val_end_time = val_data['year'].max()

# ğŸ”¥ ä»æµ‹è¯•ç«™ç‚¹ä¸­ç­›é€‰å‡ºä¸éªŒè¯é›†æ—¶é—´çª—å£ç›¸åŒçš„æ•°æ®
# è¿™ä¿è¯äº†æµ‹è¯•é›†ä¸ä¸ºç©ºï¼Œä¸”æ—¶é—´ä¸Šä¸æ³„éœ²è®­ç»ƒé›†çš„ä¿¡æ¯
test_data = test_df_sorted[
    (test_df_sorted['year'] >= val_start_time) & (test_df_sorted['year'] <= val_end_time)
].copy()

# æ‰“å°ä¸€ä¸‹æ•°æ®é›†å¤§å°ï¼Œç¡®è®¤éç©º
print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_data)}")
print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(val_data)}")
print(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_data)}") # è¿™ä¸ªæ•°ç°åœ¨åº”è¯¥ > 0 äº†


train_dataset, val_dataset, test_dataset = init_dataset_split(train_data=train_data,
                                                              val_data=val_data,
                                                              test_data=test_data,
                                                              x_column=[
                                                                  'aspect', 'slope', 'eastness', 'tpi', 'curvature1',
                                                                  'curvature2', 'elevation', 'std_slope',
                                                                  'std_eastness', 'std_tpi', 'std_curvature1',
                                                                  'std_curvature2', 'std_high', 'std_aspect', 'glsnow',
                                                                  'cswe', 'snow_depth_snow_depth',
                                                                  'ERA5æ¸©åº¦_ERA5æ¸©åº¦', 'era5_swe', 'gldas',
                                                                  'scp_start', 'scp_end',
                                                                    'd1', 'd2','da', 'db', 'dc', 'dd',
                                                                  'landuse_11', 'landuse_12', 'landuse_21',
                                                                  'landuse_22', 'landuse_23', 'landuse_24',
                                                                  'landuse_31', 'landuse_32', 'landuse_33',
                                                                  'landuse_41',  'landuse_43',
                                                                  'landuse_46', 'landuse_51', 'landuse_52',
                                                                  'landuse_53', 'landuse_62',
                                                                  'landuse_64'
                                                              ],
                                                              y_column=['swe'],
                                                              spatial_column=['X', 'Y','Z'],
                                                              temp_column=['doy','year','month'],
                                                              id_column=['id'],
                                                              use_model="gtnnwr",
                                                              batch_size=128)


optimizer_params = {
    "scheduler":"MultiStepLR",
    "scheduler_milestones":[1000, 2000, 3000, 4000],
    "scheduler_gamma":0.8,
}
gtnnwr = GTNNWR(train_dataset, val_dataset, test_dataset, [[3], [512,256,64]],drop_out=0.4,optimizer='Adadelta',optimizer_params=optimizer_params,
                write_path = "../demo_result/gtnnwr_runs", # è¿™é‡Œéœ€è¦ä¿®æ”¹
                model_name="GTNNWR_Di")
gtnnwr.add_graph()

gtnnwr.run(100,1000)

gtnnwr.result()
save_path = "../demo_result/gtnnwr_runs/GTNNWR_DSi_results.png"

metrics = plot_gtnnwr_results(gtnnwr, save_path=save_path, show_plot=True)
