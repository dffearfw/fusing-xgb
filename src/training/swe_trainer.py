import logging
import pandas as pd
import numpy as np
import xgboost as xgb
from matplotlib import pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy.stats import pearsonr
from sklearn.model_selection import LeaveOneGroupOut
import os
import joblib
import json
from datetime import datetime
import seaborn as sns
from scipy import stats

logger = logging.getLogger("SWEXGBoostTrainer")


class SWEXGBoostTrainer:
    """SWE XGBoostè®­ç»ƒå™¨ - é›†æˆæ•°æ®é¢„å¤„ç†ã€äº¤å‰éªŒè¯å’Œæ¨¡å‹è®­ç»ƒ"""

    # é»˜è®¤XGBoostå‚æ•°
    DEFAULT_PARAMS = {
        'n_estimators': 60,
        'learning_rate': 0.17,
        'max_depth': 5,
        'min_child_weight': 5,
        'gamma': 0,
        'subsample': 0.8,
        'colsample_bytree': 0.5,
        'reg_alpha': 0.05,
        'random_state': 42,
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse'
    }

    def __init__(self, params=None):
        """åˆå§‹åŒ–è®­ç»ƒå™¨

        Args:
            params (dict, optional): XGBoostå‚æ•°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å‚æ•°
        """
        self.logger = logger
        self.model = None
        self.feature_columns = None
        self.target_column = 'swe'

        # æ›´æ–°å‚æ•°
        self.params = self.DEFAULT_PARAMS.copy()
        if params:
            self.params.update(params)

        self.logger.info(f"åˆå§‹åŒ–SWE XGBoostè®­ç»ƒå™¨")
        self.logger.info(f"æ¨¡å‹å‚æ•°: {self.params}")

    def validate_data(self, df):
        """éªŒè¯è¾“å…¥æ•°æ®

        Args:
            df (pd.DataFrame): è¾“å…¥æ•°æ®

        Raises:
            ValueError: æ•°æ®éªŒè¯å¤±è´¥æ—¶æŠ›å‡º
        """
        self.logger.info("éªŒè¯è¾“å…¥æ•°æ®...")

        # æ£€æŸ¥DataFrameç±»å‹
        if not isinstance(df, pd.DataFrame):
            raise ValueError("è¾“å…¥æ•°æ®å¿…é¡»æ˜¯pandas DataFrame")

        # æ£€æŸ¥å¿…è¦åˆ—
        required_columns = ['station_id', 'date', self.target_column]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")

        # æ£€æŸ¥ç›®æ ‡å˜é‡
        swe_na_count = df[self.target_column].isna().sum()
        swe_total_count = len(df)
        if swe_na_count == swe_total_count:
            raise ValueError(f"{self.target_column}åˆ—å…¨éƒ¨ä¸ºç©ºå€¼")

        self.logger.info(f"SWEæ•°æ®å®Œæ•´æ€§: {swe_total_count - swe_na_count}/{swe_total_count} æœ‰æ•ˆ")

        # æ£€æŸ¥æ ·æœ¬æ•°é‡
        if len(df) < 10:
            raise ValueError(f"æ ·æœ¬æ•°é‡å¤ªå°‘ ({len(df)})ï¼Œè‡³å°‘éœ€è¦10ä¸ªæ ·æœ¬")

        # æ£€æŸ¥ç«™ç‚¹æ•°é‡
        station_count = df['station_id'].nunique()
        if station_count < 2:
            raise ValueError(f"ç«™ç‚¹æ•°é‡å¤ªå°‘ ({station_count})ï¼Œè‡³å°‘éœ€è¦2ä¸ªç«™ç‚¹")

        self.logger.info(f"âœ… æ•°æ®éªŒè¯é€šè¿‡: {len(df)} è¡Œ, {len(df.columns)} åˆ—, {station_count} ä¸ªç«™ç‚¹")

    def preprocess_data(self, df):
        """æ•°æ®é¢„å¤„ç†

        Args:
            df (pd.DataFrame): åŸå§‹æ•°æ®

        Returns:
            tuple: (X, y, station_groups, year_groups, feature_columns)
                  X: ç‰¹å¾çŸ©é˜µ (numpy array)
                  y: ç›®æ ‡å˜é‡ (numpy array)
                  station_groups: ç«™ç‚¹åˆ†ç»„ä¿¡æ¯
                  year_groups: å¹´ä»½åˆ†ç»„ä¿¡æ¯
                  feature_columns: ç‰¹å¾åˆ—ååˆ—è¡¨
        """
        self.logger.info("å¼€å§‹æ•°æ®é¢„å¤„ç†...")

        # éªŒè¯æ•°æ®
        self.validate_data(df)

        # åˆ›å»ºæ•°æ®å‰¯æœ¬
        df_clean = df.copy()

        # åˆ é™¤ç›®æ ‡å˜é‡ä¸ºç©ºçš„æ ·æœ¬
        initial_count = len(df_clean)
        df_clean = df_clean.dropna(subset=[self.target_column]).copy()
        removed_count = initial_count - len(df_clean)

        if removed_count > 0:
            self.logger.info(f"åˆ é™¤ {removed_count} ä¸ªSWEä¸ºç©ºå€¼çš„æ ·æœ¬")
        self.logger.info(f"å‰©ä½™æœ‰æ•ˆæ ·æœ¬: {len(df_clean)} è¡Œ")

        # ç¡®å®šç‰¹å¾åˆ—ï¼ˆæ’é™¤station_id, date, sweï¼‰
        exclude_columns = ['station_id', 'date', self.target_column]
        self.feature_columns = [col for col in df_clean.columns if col not in exclude_columns]

        if not self.feature_columns:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ç‰¹å¾åˆ—")

        self.logger.info(f"ä½¿ç”¨ {len(self.feature_columns)} ä¸ªç‰¹å¾")
        self.logger.debug(f"ç‰¹å¾åˆ—è¡¨: {self.feature_columns}")

        # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
        X = df_clean[self.feature_columns].copy()
        y = df_clean[self.target_column].copy()

        # å¤„ç†ç‰¹å¾ç¼ºå¤±å€¼
        X_processed = self._handle_missing_values(X)

        # å‡†å¤‡åˆ†ç»„ä¿¡æ¯
        df_clean['year'] = pd.to_datetime(df_clean['date']).dt.year
        station_groups = df_clean['station_id'].values
        year_groups = df_clean['year'].values

        # ç»Ÿè®¡ä¿¡æ¯
        station_count = len(np.unique(station_groups))
        year_count = len(np.unique(year_groups))
        swe_mean = y.mean()
        swe_std = y.std()

        self.logger.info("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
        self.logger.info(f"  ğŸ“Š æ ·æœ¬æ•°: {len(X_processed)}")
        self.logger.info(f"  ğŸ”§ ç‰¹å¾æ•°: {len(self.feature_columns)}")
        self.logger.info(f"  ğŸ“ ç«™ç‚¹æ•°: {station_count}")
        self.logger.info(f"  ğŸ“… å¹´ä»½æ•°: {year_count}")
        self.logger.info(f"  â„ï¸  SWEç»Ÿè®¡: å‡å€¼={swe_mean:.2f}mm, æ ‡å‡†å·®={swe_std:.2f}mm")

        return X_processed.values, y.values, station_groups, year_groups

    def _handle_missing_values(self, X):
        """å¤„ç†ç‰¹å¾ç¼ºå¤±å€¼

        Args:
            X (pd.DataFrame): ç‰¹å¾æ•°æ®

        Returns:
            pd.DataFrame: å¤„ç†åçš„ç‰¹å¾æ•°æ®
        """
        self.logger.info("å¤„ç†ç‰¹å¾ç¼ºå¤±å€¼...")

        initial_missing = X.isna().sum().sum()
        if initial_missing == 0:
            self.logger.info("æ²¡æœ‰å‘ç°ç¼ºå¤±å€¼")
            return X

        X_processed = X.copy()

        # æ•°å€¼ç‰¹å¾ç”¨ä¸­ä½æ•°å¡«å……
        numeric_cols = X_processed.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            numeric_missing = X_processed[numeric_cols].isna().sum().sum()
            if numeric_missing > 0:
                X_processed[numeric_cols] = X_processed[numeric_cols].fillna(
                    X_processed[numeric_cols].median()
                )
                self.logger.info(f"å¡«å…… {numeric_missing} ä¸ªæ•°å€¼ç‰¹å¾ç¼ºå¤±å€¼")

        # åˆ†ç±»ç‰¹å¾ç”¨ä¼—æ•°å¡«å……å¹¶ç¼–ç 
        categorical_cols = X_processed.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            col_missing = X_processed[col].isna().sum()
            if col_missing > 0:
                # ç”¨ä¼—æ•°å¡«å……ï¼Œå¦‚æœä¼—æ•°ä¸å­˜åœ¨åˆ™ç”¨'missing'
                if len(X_processed[col].mode()) > 0:
                    fill_value = X_processed[col].mode()[0]
                else:
                    fill_value = 'missing'
                X_processed[col] = X_processed[col].fillna(fill_value)
                self.logger.info(f"å¡«å……åˆ†ç±»ç‰¹å¾ '{col}' çš„ {col_missing} ä¸ªç¼ºå¤±å€¼")

            # è½¬æ¢ä¸ºæ•°å€¼ç¼–ç 
            X_processed[col] = X_processed[col].astype('category').cat.codes

        remaining_missing = X_processed.isna().sum().sum()
        if remaining_missing > 0:
            self.logger.warning(f"ä»æœ‰ {remaining_missing} ä¸ªç¼ºå¤±å€¼æœªå¤„ç†")

        return X_processed

    def evaluate_predictions(self, y_true, y_pred):
        """è¯„ä¼°é¢„æµ‹ç»“æœ

        Args:
            y_true (array-like): çœŸå®å€¼
            y_pred (array-like): é¢„æµ‹å€¼

        Returns:
            dict: åŒ…å«è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
        """
        # ç§»é™¤NaNå€¼
        mask = ~(np.isnan(y_true) | np.isnan(y_pred))
        y_true_clean = y_true[mask]
        y_pred_clean = y_pred[mask]

        if len(y_true_clean) == 0:
            return {
                'MAE': np.nan,
                'RMSE': np.nan,
                'R': np.nan,
                'R_pvalue': np.nan,
                'æ ·æœ¬æ•°': 0,
                'æ€»æ ·æœ¬æ•°': len(y_true),
                'æœ‰æ•ˆæ ·æœ¬æ¯”ä¾‹': 0.0
            }

        # è®¡ç®—MAEå’ŒRMSE
        mae = mean_absolute_error(y_true_clean, y_pred_clean)
        rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))

        # å®‰å…¨è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
        def safe_pearsonr(x, y):
            """å®‰å…¨è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°ï¼Œå¤„ç†å¸¸æ•°æ•°ç»„æƒ…å†µ"""
            # æ£€æŸ¥è¾“å…¥æ•°ç»„æ˜¯å¦ä¸ºå¸¸æ•°
            if len(x) <= 1:
                return np.nan, np.nan

            if np.all(x == x[0]) or np.all(y == y[0]):
                # å¦‚æœä»»ä¸€æ•°ç»„æ˜¯å¸¸æ•°ï¼Œç›¸å…³ç³»æ•°æœªå®šä¹‰
                return np.nan, np.nan

            # æ£€æŸ¥æ–¹å·®æ˜¯å¦ä¸º0
            if np.std(x) == 0 or np.std(y) == 0:
                return np.nan, np.nan

            try:
                return pearsonr(x, y)
            except:
                return np.nan, np.nan

        # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
        r, p_value = safe_pearsonr(y_true_clean, y_pred_clean)

        total_samples = len(y_true)
        valid_samples = len(y_true_clean)
        valid_ratio = valid_samples / total_samples if total_samples > 0 else 0

        return {
            'MAE': mae,
            'RMSE': rmse,
            'R': r,
            'R_pvalue': p_value,
            'æ ·æœ¬æ•°': valid_samples,
            'æ€»æ ·æœ¬æ•°': total_samples,
            'æœ‰æ•ˆæ ·æœ¬æ¯”ä¾‹': valid_ratio
        }

    def cross_validate(self, X, y, groups, cv_type='station'):
        """æ‰§è¡Œäº¤å‰éªŒè¯

        Args:
            X (np.array): ç‰¹å¾æ•°æ®
            y (np.array): ç›®æ ‡å˜é‡
            groups (np.array): åˆ†ç»„ä¿¡æ¯
            cv_type (str): äº¤å‰éªŒè¯ç±»å‹ ('station' æˆ– 'yearly')

        Returns:
            dict: äº¤å‰éªŒè¯ç»“æœï¼ŒåŒ…å«èšåˆå€¼ã€å¹³å‡å€¼å’Œä¸­ä½æ•°
        """
        logo = LeaveOneGroupOut()

        all_predictions = []
        all_true_values = []
        fold_results = {}

        # ç”¨äºå­˜å‚¨å„æŠ˜å çš„æŒ‡æ ‡
        fold_maes = []
        fold_rmses = []
        fold_rs = []
        fold_samples = []

        unique_groups = np.unique(groups)
        total_folds = len(unique_groups)

        self.logger.info(f"å¼€å§‹{cv_type}äº¤å‰éªŒè¯ï¼Œå…±{total_folds}ä¸ªæŠ˜å ...")

        for fold, (train_idx, test_idx) in enumerate(logo.split(X, y, groups)):
            group_id = groups[test_idx[0]]
            test_size = len(test_idx)
            train_size = len(train_idx)

            self.logger.debug(f"{cv_type} Fold {fold + 1}: è®­ç»ƒé›†{train_size}æ ·æœ¬, æµ‹è¯•é›†{test_size}æ ·æœ¬")

            # åˆ†å‰²æ•°æ®
            X_train, X_test = X[train_idx], X[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]

            # è®­ç»ƒæ¨¡å‹
            model = xgb.XGBRegressor(**self.params)
            model.fit(X_train, y_train)

            # é¢„æµ‹
            y_pred = model.predict(X_test)

            # å­˜å‚¨ç»“æœ
            all_predictions.extend(y_pred)
            all_true_values.extend(y_test)

            # è®¡ç®—å½“å‰æŠ˜å æ€§èƒ½
            fold_metrics = self.evaluate_predictions(y_test, y_pred)
            fold_results[group_id] = fold_metrics

            # å®‰å…¨æ˜¾ç¤ºç›¸å…³ç³»æ•°
            r_display = fold_metrics['R']
            if np.isnan(r_display):
                r_display_str = "NaN"
            else:
                r_display_str = f"{r_display:.3f}"

            self.logger.info(
                f"  {cv_type} Fold {fold + 1}/{total_folds}: {group_id} "
                f"({test_size}æ ·æœ¬) - "
                f"MAE={fold_metrics['MAE']:.3f}, R={r_display_str}"
            )

            # å­˜å‚¨å„æŠ˜å æŒ‡æ ‡ç”¨äºç»Ÿè®¡
            fold_maes.append(fold_metrics['MAE'])
            fold_rmses.append(fold_metrics['RMSE'])
            fold_rs.append(fold_metrics['R'])
            fold_samples.append(fold_metrics['æ ·æœ¬æ•°'])

            self.logger.info(
                f"  {cv_type} Fold {fold + 1}/{total_folds}: {group_id} "
                f"({test_size}æ ·æœ¬) - "
                f"MAE={fold_metrics['MAE']:.3f}, R={fold_metrics['R']:.3f}"
            )

        # è®¡ç®—èšåˆæ€§èƒ½ï¼ˆæ‰€æœ‰æµ‹è¯•æ ·æœ¬ä¸€èµ·è®¡ç®—ï¼‰
        overall_metrics = self.evaluate_predictions(
            np.array(all_true_values),
            np.array(all_predictions)
        )

        # è®¡ç®—å„æŠ˜å æŒ‡æ ‡çš„å¹³å‡å€¼å’Œä¸­ä½æ•°
        def safe_statistic(values, func):
            """å®‰å…¨è®¡ç®—ç»Ÿè®¡é‡ï¼Œå¤„ç†NaNå€¼"""
            valid_values = [v for v in values if not np.isnan(v)]
            if len(valid_values) == 0:
                return np.nan
            return func(valid_values)

        mean_metrics = {
            'MAE': safe_statistic(fold_maes, np.mean),
            'RMSE': safe_statistic(fold_rmses, np.mean),
            'R': safe_statistic(fold_rs, np.mean),
            'æ ·æœ¬æ•°': np.sum(fold_samples)  # æ€»æ ·æœ¬æ•°
        }

        median_metrics = {
            'MAE': safe_statistic(fold_maes, np.median),
            'RMSE': safe_statistic(fold_rmses, np.median),
            'R': safe_statistic(fold_rs, np.median),
            'æ ·æœ¬æ•°': np.sum(fold_samples)
        }

        # è®¡ç®—å„æŠ˜å æŒ‡æ ‡çš„æ ‡å‡†å·®
        std_metrics = {
            'MAE': safe_statistic(fold_maes, np.std),
            'RMSE': safe_statistic(fold_rmses, np.std),
            'R': safe_statistic(fold_rs, np.std)
        }

        # å®‰å…¨æ˜¾ç¤ºæ€»ä½“ç›¸å…³ç³»æ•°
        overall_r_display = overall_metrics['R']
        mean_r_display = mean_metrics['R']
        median_r_display = median_metrics['R']

        if np.isnan(overall_r_display):
            overall_r_str = "NaN"
        else:
            overall_r_str = f"{overall_r_display:.3f}"

        if np.isnan(mean_r_display):
            mean_r_str = "NaN"
        else:
            mean_r_str = f"{mean_r_display:.3f}"

        if np.isnan(median_r_display):
            median_r_str = "NaN"
        else:
            median_r_str = f"{median_r_display:.3f}"

        self.logger.info(f"âœ… {cv_type}äº¤å‰éªŒè¯å®Œæˆ")
        self.logger.info(f"  èšåˆæ€§èƒ½: MAE={overall_metrics['MAE']:.3f}mm, R={overall_r_str}")
        self.logger.info(f"  å¹³å‡æ€§èƒ½: MAE={mean_metrics['MAE']:.3f}mm, R={mean_r_str}")
        self.logger.info(f"  ä¸­ä½æ•°æ€§èƒ½: MAE={median_metrics['MAE']:.3f}mm, R={median_r_str}")

        return {
            'overall': overall_metrics,  # èšåˆè®¡ç®—ï¼šæ‰€æœ‰æµ‹è¯•æ ·æœ¬ä¸€èµ·è®¡ç®—
            'mean': mean_metrics,  # å¹³å‡å€¼ï¼šå„æŠ˜å æŒ‡æ ‡çš„å¹³å‡
            'median': median_metrics,  # ä¸­ä½æ•°ï¼šå„æŠ˜å æŒ‡æ ‡çš„ä¸­ä½æ•°
            'std': std_metrics,  # æ ‡å‡†å·®ï¼šå„æŠ˜å æŒ‡æ ‡çš„å˜å¼‚ç¨‹åº¦
            'by_fold': fold_results,  # å„æŠ˜å è¯¦ç»†ç»“æœ
            'predictions': np.array(all_predictions),
            'true_values': np.array(all_true_values),
            'folds': total_folds,
            'fold_metrics': {  # å„æŠ˜å æŒ‡æ ‡åˆ—è¡¨
                'MAE': fold_maes,
                'RMSE': fold_rmses,
                'R': fold_rs,
                'samples': fold_samples
            }
        }

    def safe_statistic(values, func):
        """å®‰å…¨è®¡ç®—ç»Ÿè®¡é‡ï¼Œå¤„ç†NaNå€¼å’Œç©ºæ•°ç»„"""
        valid_values = [v for v in values if not np.isnan(v)]
        if len(valid_values) == 0:
            return np.nan
        return func(valid_values)

    def train_final_model(self, X, y):
        """è®­ç»ƒæœ€ç»ˆæ¨¡å‹

        Args:
            X (np.array): ç‰¹å¾æ•°æ®
            y (np.array): ç›®æ ‡å˜é‡

        Returns:
            xgb.XGBRegressor: è®­ç»ƒå¥½çš„XGBoostæ¨¡å‹
        """
        self.logger.info("è®­ç»ƒæœ€ç»ˆXGBoostæ¨¡å‹...")

        self.model = xgb.XGBRegressor(**self.params)
        self.model.fit(X, y)

        self.logger.info("âœ… æœ€ç»ˆæ¨¡å‹è®­ç»ƒå®Œæˆ")
        return self.model

    def get_feature_importance(self):
        """è·å–ç‰¹å¾é‡è¦æ€§

        Returns:
            pd.DataFrame: ç‰¹å¾é‡è¦æ€§æ’åºï¼ŒåŒ…å«'feature'å’Œ'importance'åˆ—
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ train_final_model æ–¹æ³•")

        importance_scores = self.model.feature_importances_

        feature_importance_df = pd.DataFrame({
            'feature': self.feature_columns,
            'importance': importance_scores
        }).sort_values('importance', ascending=False)

        self.logger.info(f"ç‰¹å¾é‡è¦æ€§è®¡ç®—å®Œæˆï¼Œæœ€é«˜é‡è¦æ€§: {feature_importance_df['importance'].iloc[0]:.4f}")

        return feature_importance_df

    def run_complete_analysis(self, df, output_dir=None):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹

        Args:
            df (pd.DataFrame): è¾“å…¥æ•°æ®
            output_dir (str, optional): è¾“å‡ºç›®å½•è·¯å¾„

        Returns:
            dict: åŒ…å«æ‰€æœ‰åˆ†æç»“æœçš„å­—å…¸
        """
        self.logger.info("=" * 70)
        self.logger.info("ğŸš€ å¼€å§‹SWE XGBoostå®Œæ•´åˆ†ææµç¨‹")
        self.logger.info("=" * 70)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        if output_dir is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_dir = f"./swe_model_results_{timestamp}"

        os.makedirs(output_dir, exist_ok=True)
        self.logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")

        try:
            # 1. æ•°æ®é¢„å¤„ç†
            self.logger.info("\n" + "=" * 50)
            self.logger.info("æ­¥éª¤ 1: æ•°æ®é¢„å¤„ç†")
            self.logger.info("=" * 50)

            X, y, station_groups, year_groups = self.preprocess_data(df)

            results = {
                'preprocessing': {
                    'samples': len(X),
                    'features': len(self.feature_columns),
                    'stations': len(np.unique(station_groups)),
                    'years': len(np.unique(year_groups))
                }
            }

            # 2. ç«™ç‚¹äº¤å‰éªŒè¯
            self.logger.info("\n" + "=" * 50)
            self.logger.info("æ­¥éª¤ 2: ç«™ç‚¹äº¤å‰éªŒè¯")
            self.logger.info("=" * 50)

            results['station_cv'] = self.cross_validate(X, y, station_groups, 'station')

            # 3. å¹´åº¦äº¤å‰éªŒè¯
            self.logger.info("\n" + "=" * 50)
            self.logger.info("æ­¥éª¤ 3: å¹´åº¦äº¤å‰éªŒè¯")
            self.logger.info("=" * 50)

            results['yearly_cv'] = self.cross_validate(X, y, year_groups, 'yearly')

            # 4. è®­ç»ƒæœ€ç»ˆæ¨¡å‹
            self.logger.info("\n" + "=" * 50)
            self.logger.info("æ­¥éª¤ 4: è®­ç»ƒæœ€ç»ˆæ¨¡å‹")
            self.logger.info("=" * 50)

            results['final_model'] = self.train_final_model(X, y)

            # 5. ç‰¹å¾é‡è¦æ€§åˆ†æ
            self.logger.info("\n" + "=" * 50)
            self.logger.info("æ­¥éª¤ 5: ç‰¹å¾é‡è¦æ€§åˆ†æ")
            self.logger.info("=" * 50)

            results['feature_importance'] = self.get_feature_importance()

            # 6. ä¿å­˜ç»“æœ
            self.logger.info("\n" + "=" * 50)
            self.logger.info("æ­¥éª¤ 6: ä¿å­˜ç»“æœ")
            self.logger.info("=" * 50)

            self._save_results(results, output_dir)

            # 7. ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report(results)
            print(report)
            self.logger.info("ğŸ¯ å®Œæ•´åˆ†æå®Œæˆï¼")
            return results

        except Exception as e:
            self.logger.error(f"âŒ åˆ†ææµç¨‹å¤±è´¥: {str(e)}")
            raise

    def _create_scatter_plots(self, results, output_dir):
        """åˆ›å»ºä¸¤ç§äº¤å‰éªŒè¯æ–¹æ³•çš„é¢„æµ‹å€¼ä¸å®é™…å€¼æ•£ç‚¹å›¾

        Args:
            results (dict): åˆ†æç»“æœ
            output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
        """
        try:
            self.logger.info("ğŸ“Š ç”Ÿæˆæ•£ç‚¹å›¾...")

            # è®¾ç½®å›¾å½¢æ ·å¼
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'Arial']
            plt.rcParams['axes.unicode_minus'] = False
            sns.set_style("whitegrid")

            # åˆ›å»ºå­å›¾
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

            # ç«™ç‚¹äº¤å‰éªŒè¯æ•£ç‚¹å›¾
            if 'station_cv' in results:
                self._plot_single_scatter(
                    ax1,
                    results['station_cv']['true_values'],
                    results['station_cv']['predictions'],
                    results['station_cv']['overall'],
                    'ç«™ç‚¹äº¤å‰éªŒè¯',
                    'XGBoost SWE based on site cross-validation (mm)'
                )

            # å¹´åº¦äº¤å‰éªŒè¯æ•£ç‚¹å›¾
            if 'yearly_cv' in results:
                self._plot_single_scatter(
                    ax2,
                    results['yearly_cv']['true_values'],
                    results['yearly_cv']['predictions'],
                    results['yearly_cv']['overall'],
                    'å¹´åº¦äº¤å‰éªŒè¯',
                    'XGBoost SWE based on annual cross-validation (mm)'
                )

            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()

            # ä¿å­˜å›¾ç‰‡
            scatter_path = f'{output_dir}/scatter_plots.png'
            plt.savefig(scatter_path, dpi=300, bbox_inches='tight')
            plt.close()

            self.logger.info(f"âœ… æ•£ç‚¹å›¾ä¿å­˜: {scatter_path}")

        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆæ•£ç‚¹å›¾å¤±è´¥: {str(e)}")

    def _plot_single_scatter(self, ax, y_true, y_pred, metrics, title, ylabel):
        """ç»˜åˆ¶å•ä¸ªæ•£ç‚¹å›¾

        Args:
            ax: matplotlibè½´å¯¹è±¡
            y_true: çœŸå®å€¼æ•°ç»„
            y_pred: é¢„æµ‹å€¼æ•°ç»„
            metrics: è¯„ä¼°æŒ‡æ ‡å­—å…¸
            title: å›¾æ ‡é¢˜
            ylabel: çºµåæ ‡æ ‡ç­¾
        """
        # ç§»é™¤NaNå€¼
        mask = ~(np.isnan(y_true) | np.isnan(y_pred))
        y_true_clean = y_true[mask]
        y_pred_clean = y_pred[mask]

        if len(y_true_clean) == 0:
            ax.text(0.5, 0.5, 'æ— æœ‰æ•ˆæ•°æ®', ha='center', va='center', transform=ax.transAxes)
            ax.set_title(title)
            return

        # è®¾ç½®åæ ‡è½´èŒƒå›´åˆ°175mm
        max_range = 175
        min_val = 0
        max_val = max_range

        # 1:1 å‚è€ƒçº¿ - é»‘è‰²å®çº¿ï¼ˆä¸æ˜¾ç¤ºåœ¨å›¾ä¾‹ä¸­ï¼‰
        ax.plot([min_val, max_val], [min_val, max_val], 'k-', alpha=0.8, linewidth=2)

        # ä½¿ç”¨æ¸…æ™°çš„æ•£ç‚¹å›¾ï¼Œæ ¹æ®å¯†åº¦ç€è‰²
        try:
            # ä½¿ç”¨2Dæ ¸å¯†åº¦ä¼°è®¡æ¥ç€è‰²
            from scipy.stats import gaussian_kde

            # è®¡ç®—ç‚¹çš„å¯†åº¦
            xy = np.vstack([y_true_clean, y_pred_clean])
            z = gaussian_kde(xy)(xy)

            # æŒ‰å¯†åº¦æ’åºï¼Œç¡®ä¿é«˜å¯†åº¦ç‚¹åœ¨ä¸Šå±‚
            idx = z.argsort()
            y_true_sorted, y_pred_sorted, z_sorted = y_true_clean[idx], y_pred_clean[idx], z[idx]

            # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼Œä½¿ç”¨æ¸…æ™°çš„ç‚¹
            scatter = ax.scatter(y_true_sorted, y_pred_sorted,
                                 c=z_sorted,
                                 cmap='viridis',  # æ¸…æ™°çš„è“-é»„é¢œè‰²æ˜ å°„
                                 s=15,  # é€‚å½“å¤§å°çš„ç‚¹
                                 alpha=0.7,  # é€‚å½“çš„é€æ˜åº¦
                                 edgecolors='none',  # æ— è¾¹æ¡†
                                 marker='o')  # åœ†å½¢ç‚¹

            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(scatter, ax=ax, label='ç‚¹å¯†åº¦')

        except Exception as e:
            self.logger.warning(f"å¯†åº¦ç€è‰²å¤±è´¥ï¼Œä½¿ç”¨æ™®é€šæ•£ç‚¹å›¾: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šæ™®é€šæ•£ç‚¹å›¾
            scatter = ax.scatter(y_true_clean, y_pred_clean,
                                 alpha=0.6, s=15, c='blue', edgecolors='none')

        # æ·»åŠ å›å½’è¶‹åŠ¿çº¿ï¼ˆè™šçº¿ï¼‰
        if len(y_true_clean) > 1:
            try:
                # è®¡ç®—çº¿æ€§å›å½’
                slope, intercept, r_value, p_value, std_err = stats.linregress(y_true_clean, y_pred_clean)

                # ç”Ÿæˆå›å½’çº¿æ•°æ®ç‚¹
                x_reg = np.linspace(min_val, max_val, 100)
                y_reg = slope * x_reg + intercept

                # ç»˜åˆ¶å›å½’çº¿ - çº¢è‰²è™šçº¿ï¼ˆä¸æ˜¾ç¤ºåœ¨å›¾ä¾‹ä¸­ï¼‰
                ax.plot(x_reg, y_reg, 'r--', alpha=0.8, linewidth=2)

            except Exception as e:
                self.logger.warning(f"è®¡ç®—å›å½’çº¿å¤±è´¥: {e}")

        # è®¾ç½®åæ ‡è½´
        ax.set_xlabel('å®é™… SWE (mm)')
        ax.set_ylabel(ylabel)
        ax.set_title(title, fontsize=14, fontweight='bold')

        # è®¾ç½®åæ ‡è½´èŒƒå›´
        ax.set_xlim([min_val, max_val])
        ax.set_ylim([min_val, max_val])
        ax.set_aspect('equal')

        # æ·»åŠ ç½‘æ ¼
        ax.grid(True, alpha=0.3)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡† - ç§»åˆ°å³ä¸Šè§’ï¼Œæ— è¾¹æ¡†ï¼Œæ”¾å¤§å­—ä½“
        mae = metrics['MAE']
        rmse = metrics['RMSE']
        r = metrics['R']
        n = metrics['æ ·æœ¬æ•°']

        # å®‰å…¨å¤„ç†ç›¸å…³ç³»æ•°æ˜¾ç¤º
        if np.isnan(r):
            r_str = "NaN"
        else:
            r_str = f"{r:.3f}"

        stats_text = f'MAE = {mae:.2f} mm\nRMSE = {rmse:.2f} mm\nR = {r_str}\nN = {n}'

        # å³ä¸Šè§’ï¼Œæ— è¾¹æ¡†ï¼Œæ”¾å¤§å­—ä½“
        ax.text(0.95, 0.95, stats_text, transform=ax.transAxes,
                verticalalignment='top', horizontalalignment='right',
                fontsize=12,  # æ”¾å¤§å­—ä½“
                fontfamily='monospace',
                weight='bold')  # åŠ ç²—

    def _create_combined_scatter_plot(self, results, output_dir):
        """åˆ›å»ºåˆå¹¶çš„æ•£ç‚¹å›¾ï¼ˆä¸¤ç§æ–¹æ³•åœ¨åŒä¸€å›¾ä¸­ï¼‰

        Args:
            results (dict): åˆ†æç»“æœ
            output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
        """
        try:
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'Arial']
            plt.rcParams['axes.unicode_minus'] = False

            fig, ax = plt.subplots(figsize=(10, 8))

            # è®¾ç½®åæ ‡è½´èŒƒå›´åˆ°175mm
            max_range = 175
            min_val = 0
            max_val = max_range

            # 1:1 å‚è€ƒçº¿ - é»‘è‰²å®çº¿
            ax.plot([min_val, max_val], [min_val, max_val], 'k-', alpha=0.8, linewidth=2)

            colors = ['#1f77b4', '#ff7f0e']  # æ¸…æ™°çš„è“è‰²å’Œæ©™è‰²
            labels = ['ç«™ç‚¹CV', 'å¹´åº¦CV']
            methods = ['station_cv', 'yearly_cv']

            # æ”¶é›†æ‰€æœ‰ç‚¹ç”¨äºå¯†åº¦è®¡ç®—
            all_true = []
            all_pred = []
            all_colors = []

            for i, method in enumerate(methods):
                if method in results:
                    y_true = results[method]['true_values']
                    y_pred = results[method]['predictions']

                    mask = ~(np.isnan(y_true) | np.isnan(y_pred))
                    y_true_clean = y_true[mask]
                    y_pred_clean = y_pred[mask]

                    if len(y_true_clean) > 0:
                        # ä¸ºæ¯ç§æ–¹æ³•æ·»åŠ ç‚¹
                        scatter = ax.scatter(y_true_clean, y_pred_clean,
                                             c=colors[i],
                                             s=15,
                                             alpha=0.6,
                                             edgecolors='none',
                                             marker='o',
                                             label=labels[i])

                        all_true.extend(y_true_clean)
                        all_pred.extend(y_pred_clean)
                        all_colors.extend([colors[i]] * len(y_true_clean))

            if len(all_true) == 0:
                ax.text(0.5, 0.5, 'æ— æœ‰æ•ˆæ•°æ®', ha='center', va='center', transform=ax.transAxes)
                plt.savefig(f'{output_dir}/combined_scatter_plot.png', dpi=300, bbox_inches='tight')
                plt.close()
                return

            # åˆ†åˆ«è®¡ç®—ä¸¤ç§æ–¹æ³•çš„å›å½’çº¿
            for i, method in enumerate(methods):
                if method in results:
                    y_true = results[method]['true_values']
                    y_pred = results[method]['predictions']

                    mask = ~(np.isnan(y_true) | np.isnan(y_pred))
                    y_true_clean = y_true[mask]
                    y_pred_clean = y_pred[mask]

                    if len(y_true_clean) > 1:
                        try:
                            slope, intercept, r_value, p_value, std_err = stats.linregress(y_true_clean, y_pred_clean)

                            x_reg = np.linspace(min_val, max_val, 100)
                            y_reg = slope * x_reg + intercept

                            # ä½¿ç”¨ä¸åŒçº¿å‹
                            linestyle = '--' if i == 0 else '-.'
                            ax.plot(x_reg, y_reg, color=colors[i], linestyle=linestyle,
                                    alpha=0.8, linewidth=2)
                        except Exception as e:
                            self.logger.warning(f"è®¡ç®—{method}å›å½’çº¿å¤±è´¥: {e}")

            # è®¾ç½®åæ ‡è½´
            ax.set_xlim([min_val, max_val])
            ax.set_ylim([min_val, max_val])
            ax.set_aspect('equal')
            ax.set_xlabel('å®é™… SWE (mm)')
            ax.set_ylabel('é¢„æµ‹ SWE (mm)')
            ax.set_title('SWEé¢„æµ‹å€¼ä¸å®é™…å€¼æ•£ç‚¹å›¾æ¯”è¾ƒ', fontsize=14, fontweight='bold')
            ax.grid(True, alpha=0.3)

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯ - å³ä¸Šè§’ï¼Œæ— è¾¹æ¡†ï¼Œæ”¾å¤§å­—ä½“
            stats_text = ""
            if 'station_cv' in results:
                station_metrics = results['station_cv']['overall']
                station_r = station_metrics['R']
                station_r_str = f"{station_r:.3f}" if not np.isnan(station_r) else "NaN"
                stats_text += f"ç«™ç‚¹CV:\nMAE={station_metrics['MAE']:.2f}\nRMSE={station_metrics['RMSE']:.2f}\nR={station_r_str}\nN={station_metrics['æ ·æœ¬æ•°']}\n\n"

            if 'yearly_cv' in results:
                yearly_metrics = results['yearly_cv']['overall']
                yearly_r = yearly_metrics['R']
                yearly_r_str = f"{yearly_r:.3f}" if not np.isnan(yearly_r) else "NaN"
                stats_text += f"å¹´åº¦CV:\nMAE={yearly_metrics['MAE']:.2f}\nRMSE={yearly_metrics['RMSE']:.2f}\nR={yearly_r_str}\nN={yearly_metrics['æ ·æœ¬æ•°']}"

            ax.text(0.95, 0.95, stats_text, transform=ax.transAxes,
                    verticalalignment='top', horizontalalignment='right',
                    fontsize=11,
                    fontfamily='monospace',
                    weight='bold')

            # æ·»åŠ ç®€å•çš„å›¾ä¾‹ï¼ˆåªæ˜¾ç¤ºç‚¹ï¼Œä¸æ˜¾ç¤ºçº¿ï¼‰
            ax.legend(loc='lower left', framealpha=0.9)

            plt.tight_layout()
            combined_path = f'{output_dir}/combined_scatter_plot.png'
            plt.savefig(combined_path, dpi=300, bbox_inches='tight')
            plt.close()

            self.logger.info(f"âœ… åˆå¹¶æ•£ç‚¹å›¾ä¿å­˜: {combined_path}")

        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆåˆå¹¶æ•£ç‚¹å›¾å¤±è´¥: {str(e)}")

    def _save_results(self, results, output_dir):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶

        Args:
            results (dict): åˆ†æç»“æœ
            output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
        """
        try:
            self.logger.info("ğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")

            # 1. ä¿å­˜æœ€ç»ˆæ¨¡å‹
            if 'final_model' in results:
                model_path = f'{output_dir}/final_model.pkl'
                joblib.dump(results['final_model'], model_path)
                self.logger.info(f"âœ… æ¨¡å‹ä¿å­˜: {model_path}")

            # 2. ä¿å­˜ç«™ç‚¹äº¤å‰éªŒè¯é¢„æµ‹ç»“æœ
            if 'station_cv' in results:
                station_pred_df = pd.DataFrame({
                    'true_swe': results['station_cv']['true_values'],
                    'predicted_swe': results['station_cv']['predictions']
                })
                station_pred_path = f'{output_dir}/station_cv_predictions.csv'
                station_pred_df.to_csv(station_pred_path, index=False)
                self.logger.info(f"âœ… ç«™ç‚¹CVé¢„æµ‹ç»“æœä¿å­˜: {station_pred_path}")

                # ä¿å­˜ç«™ç‚¹CVå„æŠ˜å è¯¦ç»†ç»“æœ
                station_fold_results = []
                for station_id, metrics in results['station_cv']['by_fold'].items():
                    station_fold_results.append({
                        'station_id': station_id,
                        'mae': metrics['MAE'],
                        'rmse': metrics['RMSE'],
                        'r': metrics['R'],
                        'samples': metrics['æ ·æœ¬æ•°']
                    })
                station_fold_df = pd.DataFrame(station_fold_results)
                station_fold_path = f'{output_dir}/station_cv_fold_results.csv'
                station_fold_df.to_csv(station_fold_path, index=False)
                self.logger.info(f"âœ… ç«™ç‚¹CVå„æŠ˜å ç»“æœä¿å­˜: {station_fold_path}")

            # 3. ä¿å­˜å¹´åº¦äº¤å‰éªŒè¯é¢„æµ‹ç»“æœ
            if 'yearly_cv' in results:
                yearly_pred_df = pd.DataFrame({
                    'true_swe': results['yearly_cv']['true_values'],
                    'predicted_swe': results['yearly_cv']['predictions']
                })
                yearly_pred_path = f'{output_dir}/yearly_cv_predictions.csv'
                yearly_pred_df.to_csv(yearly_pred_path, index=False)
                self.logger.info(f"âœ… å¹´åº¦CVé¢„æµ‹ç»“æœä¿å­˜: {yearly_pred_path}")

                # ä¿å­˜å¹´åº¦CVå„æŠ˜å è¯¦ç»†ç»“æœ
                yearly_fold_results = []
                for year, metrics in results['yearly_cv']['by_fold'].items():
                    yearly_fold_results.append({
                        'year': year,
                        'mae': metrics['MAE'],
                        'rmse': metrics['RMSE'],
                        'r': metrics['R'],
                        'samples': metrics['æ ·æœ¬æ•°']
                    })
                yearly_fold_df = pd.DataFrame(yearly_fold_results)
                yearly_fold_path = f'{output_dir}/yearly_cv_fold_results.csv'
                yearly_fold_df.to_csv(yearly_fold_path, index=False)
                self.logger.info(f"âœ… å¹´åº¦CVå„æŠ˜å ç»“æœä¿å­˜: {yearly_fold_path}")

            # 4. ä¿å­˜ç‰¹å¾é‡è¦æ€§
            if 'feature_importance' in results:
                feature_path = f'{output_dir}/feature_importance.csv'
                results['feature_importance'].to_csv(feature_path, index=False)
                self.logger.info(f"âœ… ç‰¹å¾é‡è¦æ€§ä¿å­˜: {feature_path}")

            # 5. ä¿å­˜è¯¦ç»†çš„è¯„ä¼°ç»“æœï¼ˆJSONæ ¼å¼ï¼‰
            eval_results = {
                'training_info': {
                    'timestamp': datetime.now().isoformat(),
                    'feature_columns': self.feature_columns,
                    'total_samples': results.get('preprocessing', {}).get('samples', 0),
                    'total_stations': results.get('preprocessing', {}).get('stations', 0),
                    'total_years': results.get('preprocessing', {}).get('years', 0)
                },
                'model_parameters': self.params,
                'station_cross_validation': {
                    'overall': results['station_cv']['overall'],
                    'mean': results['station_cv']['mean'],
                    'median': results['station_cv']['median'],
                    'std': results['station_cv']['std'],
                    'folds': results['station_cv']['folds'],
                    'fold_metrics': results['station_cv']['fold_metrics'],
                    'by_fold': {str(k): v for k, v in results['station_cv']['by_fold'].items()}
                },
                'yearly_cross_validation': {
                    'overall': results['yearly_cv']['overall'],
                    'mean': results['yearly_cv']['mean'],
                    'median': results['yearly_cv']['median'],
                    'std': results['yearly_cv']['std'],
                    'folds': results['yearly_cv']['folds'],
                    'fold_metrics': results['yearly_cv']['fold_metrics'],
                    'by_fold': {str(k): v for k, v in results['yearly_cv']['by_fold'].items()}
                },
                'performance_comparison': {
                    'station_better_mae': results['station_cv']['overall']['MAE'] < results['yearly_cv']['overall'][
                        'MAE'],
                    'station_better_rmse': results['station_cv']['overall']['RMSE'] < results['yearly_cv']['overall'][
                        'RMSE'],
                    'station_better_r': results['station_cv']['overall']['R'] > results['yearly_cv']['overall']['R'],
                    'recommended_method': 'station' if results['station_cv']['overall']['R'] >
                                                       results['yearly_cv']['overall']['R'] else 'yearly'
                }
            }

            eval_path = f'{output_dir}/evaluation_results.json'
            with open(eval_path, 'w', encoding='utf-8') as f:
                json.dump(eval_results, f, indent=2, ensure_ascii=False, default=float)
            self.logger.info(f"âœ… è¯¦ç»†è¯„ä¼°ç»“æœä¿å­˜: {eval_path}")

            # 6. ä¿å­˜æ±‡æ€»æŠ¥å‘Šï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
            summary_report = self._generate_summary_report(results)
            summary_path = f'{output_dir}/model_summary_report.txt'
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(summary_report)
            self.logger.info(f"âœ… æ±‡æ€»æŠ¥å‘Šä¿å­˜: {summary_path}")

            # 7. ä¿å­˜è®­ç»ƒé…ç½®
            config_info = {
                'training_config': {
                    'model_type': 'XGBoost',
                    'target_variable': 'swe',
                    'cross_validation_methods': ['station_loocv', 'yearly_loocv'],
                    'evaluation_metrics': ['MAE', 'RMSE', 'R'],
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                },
                'feature_info': {
                    'total_features': len(self.feature_columns),
                    'feature_list': self.feature_columns
                }
            }

            config_path = f'{output_dir}/training_config.json'
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config_info, f, indent=2, ensure_ascii=False)
            self.logger.info(f"âœ… è®­ç»ƒé…ç½®ä¿å­˜: {config_path}")

            # 8. åˆ›å»ºç»“æœæ‘˜è¦æ–‡ä»¶
            self._create_results_summary(results, output_dir)

            # 9. ç”Ÿæˆæ•£ç‚¹å›¾
            self.logger.info("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
            self._create_scatter_plots(results, output_dir)
            self._create_combined_scatter_plot(results, output_dir)

            self.logger.info(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
            raise

    def _generate_summary_report(self, results):
        """ç”Ÿæˆç®€åŒ–çš„æ±‡æ€»æŠ¥å‘Šç”¨äºä¿å­˜

        Args:
            results (dict): åˆ†æç»“æœ

        Returns:
            str: æ±‡æ€»æŠ¥å‘Šæ–‡æœ¬
        """
        report_lines = []
        report_lines.append("SWEæ¨¡å‹è®­ç»ƒæ±‡æ€»æŠ¥å‘Š")
        report_lines.append("=" * 50)
        report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")

        # åŸºæœ¬ç»Ÿè®¡
        if 'preprocessing' in results:
            preproc = results['preprocessing']
            report_lines.append("åŸºæœ¬ç»Ÿè®¡:")
            report_lines.append(f"  æ€»æ ·æœ¬æ•°: {preproc['samples']}")
            report_lines.append(f"  ç‰¹å¾æ•°é‡: {preproc['features']}")
            report_lines.append(f"  ç«™ç‚¹æ•°é‡: {preproc['stations']}")
            report_lines.append(f"  å¹´ä»½æ•°é‡: {preproc['years']}")
            report_lines.append("")

        # ç«™ç‚¹äº¤å‰éªŒè¯ç»“æœ
        if 'station_cv' in results:
            station = results['station_cv']
            report_lines.append("ç«™ç‚¹äº¤å‰éªŒè¯:")
            report_lines.append(f"  æŠ˜å æ•°: {station['folds']}")
            report_lines.append(f"  èšåˆMAE: {station['overall']['MAE']:.3f} mm")
            report_lines.append(f"  å¹³å‡MAE: {station['mean']['MAE']:.3f} mm")
            report_lines.append(f"  ä¸­ä½æ•°MAE: {station['median']['MAE']:.3f} mm")
            report_lines.append(f"  èšåˆR: {station['overall']['R']:.3f}")
            report_lines.append(f"  å¹³å‡R: {station['mean']['R']:.3f}")
            report_lines.append(f"  ä¸­ä½æ•°R: {station['median']['R']:.3f}")
            report_lines.append("")

        # å¹´åº¦äº¤å‰éªŒè¯ç»“æœ
        if 'yearly_cv' in results:
            yearly = results['yearly_cv']
            report_lines.append("å¹´åº¦äº¤å‰éªŒè¯:")
            report_lines.append(f"  æŠ˜å æ•°: {yearly['folds']}")
            report_lines.append(f"  èšåˆMAE: {yearly['overall']['MAE']:.3f} mm")
            report_lines.append(f"  å¹³å‡MAE: {yearly['mean']['MAE']:.3f} mm")
            report_lines.append(f"  ä¸­ä½æ•°MAE: {yearly['median']['MAE']:.3f} mm")
            report_lines.append(f"  èšåˆR: {yearly['overall']['R']:.3f}")
            report_lines.append(f"  å¹³å‡R: {yearly['mean']['R']:.3f}")
            report_lines.append(f"  ä¸­ä½æ•°R: {yearly['median']['R']:.3f}")
            report_lines.append("")

        # ç‰¹å¾é‡è¦æ€§
        if 'feature_importance' in results:
            top_features = results['feature_importance'].head(10)
            report_lines.append("å‰10ä¸ªé‡è¦ç‰¹å¾:")
            for i, (_, row) in enumerate(top_features.iterrows(), 1):
                report_lines.append(f"  {i:2d}. {row['feature']:<20} {row['importance']:.4f}")

        return "\n".join(report_lines)

    def _create_results_summary(self, results, output_dir):
        """åˆ›å»ºç»“æœæ‘˜è¦æ–‡ä»¶ï¼ˆCSVæ ¼å¼ï¼Œä¾¿äºåˆ†æï¼‰

        Args:
            results (dict): åˆ†æç»“æœ
            output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
        """
        try:
            # åˆ›å»ºæ€§èƒ½æ¯”è¾ƒæ‘˜è¦
            summary_data = []

            # ç«™ç‚¹CVæ‘˜è¦
            if 'station_cv' in results:
                station = results['station_cv']
                summary_data.append({
                    'method': 'station_cv',
                    'folds': station['folds'],
                    'overall_mae': station['overall']['MAE'],
                    'overall_rmse': station['overall']['RMSE'],
                    'overall_r': station['overall']['R'],
                    'mean_mae': station['mean']['MAE'],
                    'mean_rmse': station['mean']['RMSE'],
                    'mean_r': station['mean']['R'],
                    'median_mae': station['median']['MAE'],
                    'median_rmse': station['median']['RMSE'],
                    'median_r': station['median']['R'],
                    'std_mae': station['std']['MAE'],
                    'std_rmse': station['std']['RMSE'],
                    'std_r': station['std']['R'],
                    'samples': station['overall']['æ ·æœ¬æ•°']
                })

            # å¹´åº¦CVæ‘˜è¦
            if 'yearly_cv' in results:
                yearly = results['yearly_cv']
                summary_data.append({
                    'method': 'yearly_cv',
                    'folds': yearly['folds'],
                    'overall_mae': yearly['overall']['MAE'],
                    'overall_rmse': yearly['overall']['RMSE'],
                    'overall_r': yearly['overall']['R'],
                    'mean_mae': yearly['mean']['MAE'],
                    'mean_rmse': yearly['mean']['RMSE'],
                    'mean_r': yearly['mean']['R'],
                    'median_mae': yearly['median']['MAE'],
                    'median_rmse': yearly['median']['RMSE'],
                    'median_r': yearly['median']['R'],
                    'std_mae': yearly['std']['MAE'],
                    'std_rmse': yearly['std']['RMSE'],
                    'std_r': yearly['std']['R'],
                    'samples': yearly['overall']['æ ·æœ¬æ•°']
                })

            # ä¿å­˜æ‘˜è¦
            summary_df = pd.DataFrame(summary_data)
            summary_path = f'{output_dir}/performance_summary.csv'
            summary_df.to_csv(summary_path, index=False)
            self.logger.info(f"âœ… æ€§èƒ½æ‘˜è¦ä¿å­˜: {summary_path}")

        except Exception as e:
            self.logger.warning(f"åˆ›å»ºç»“æœæ‘˜è¦å¤±è´¥: {str(e)}")

    def _generate_report(self, results):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š

        Args:
            results (dict): åˆ†æç»“æœ

        Returns:
            str: æ ¼å¼åŒ–çš„æŠ¥å‘Šæ–‡æœ¬
        """
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("ğŸ“Š SWE XGBoostæ¨¡å‹åˆ†ææŠ¥å‘Š - è¯¦ç»†ç»Ÿè®¡")
        report_lines.append("=" * 80)

        # åŸºæœ¬ä¿¡æ¯
        report_lines.append(f"\nğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
        report_lines.append(f"  è®­ç»ƒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"  ç‰¹å¾æ•°é‡: {len(self.feature_columns)}")

        if 'preprocessing' in results:
            preproc = results['preprocessing']
            report_lines.append(f"  æ ·æœ¬æ•°é‡: {preproc['samples']}")
            report_lines.append(f"  ç«™ç‚¹æ•°é‡: {preproc['stations']}")
            report_lines.append(f"  å¹´ä»½æ•°é‡: {preproc['years']}")

        # ç«™ç‚¹äº¤å‰éªŒè¯ç»“æœ
        if 'station_cv' in results:
            station_overall = results['station_cv']['overall']
            station_mean = results['station_cv']['mean']
            station_median = results['station_cv']['median']
            station_std = results['station_cv']['std']

            # å®‰å…¨å¤„ç†ç›¸å…³ç³»æ•°æ˜¾ç¤º
            station_overall_r = station_overall['R']
            station_mean_r = station_mean['R']
            station_median_r = station_median['R']

            station_overall_r_str = f"{station_overall_r:.3f}" if not np.isnan(station_overall_r) else "NaN"
            station_mean_r_str = f"{station_mean_r:.3f}" if not np.isnan(station_mean_r) else "NaN"
            station_median_r_str = f"{station_median_r:.3f}" if not np.isnan(station_median_r) else "NaN"

            report_lines.append(f"\nğŸ“ ç«™ç‚¹äº¤å‰éªŒè¯ (ç©ºé—´è¯„ä¼°):")
            report_lines.append(f"  â”Œ{'â”€' * 20}â”¬{'â”€' * 10}â”¬{'â”€' * 10}â”¬{'â”€' * 10}â”")
            report_lines.append(f"  â”‚ {'æŒ‡æ ‡':18} â”‚ {'èšåˆ':8} â”‚ {'å¹³å‡':8} â”‚ {'ä¸­ä½æ•°':8} â”‚")
            report_lines.append(f"  â”œ{'â”€' * 20}â”¼{'â”€' * 10}â”¼{'â”€' * 10}â”¼{'â”€' * 10}â”¤")
            report_lines.append(
                f"  â”‚ {'MAE (mm)':18} â”‚ {station_overall['MAE']:8.3f} â”‚ {station_mean['MAE']:8.3f} â”‚ {station_median['MAE']:8.3f} â”‚")
            report_lines.append(
                f"  â”‚ {'RMSE (mm)':18} â”‚ {station_overall['RMSE']:8.3f} â”‚ {station_mean['RMSE']:8.3f} â”‚ {station_median['RMSE']:8.3f} â”‚")
            report_lines.append(
                f"  â”‚ {'R':18} â”‚ {station_overall_r_str:>8} â”‚ {station_mean_r_str:>8} â”‚ {station_median_r_str:>8} â”‚")
            report_lines.append(f"  â””{'â”€' * 20}â”´{'â”€' * 10}â”´{'â”€' * 10}â”´{'â”€' * 10}â”˜")

            report_lines.append(f"  æŠ˜å æ•°: {results['station_cv']['folds']}")
            report_lines.append(f"  æ ·æœ¬æ•°: {station_overall['æ ·æœ¬æ•°']}")

            # æ·»åŠ æ ‡å‡†å·®ä¿¡æ¯
            report_lines.append(
                f"  å„æŠ˜å æ ‡å‡†å·®: MAEÂ±{station_std['MAE']:.3f}, RMSEÂ±{station_std['RMSE']:.3f}, RÂ±{station_std['R']:.3f}")

        # å¹´åº¦äº¤å‰éªŒè¯ç»“æœ
        if 'yearly_cv' in results:
            yearly_overall = results['yearly_cv']['overall']
            yearly_mean = results['yearly_cv']['mean']
            yearly_median = results['yearly_cv']['median']
            yearly_std = results['yearly_cv']['std']

            # å®‰å…¨å¤„ç†ç›¸å…³ç³»æ•°æ˜¾ç¤º
            yearly_overall_r = yearly_overall['R']
            yearly_mean_r = yearly_mean['R']
            yearly_median_r = yearly_median['R']

            yearly_overall_r_str = f"{yearly_overall_r:.3f}" if not np.isnan(yearly_overall_r) else "NaN"
            yearly_mean_r_str = f"{yearly_mean_r:.3f}" if not np.isnan(yearly_mean_r) else "NaN"
            yearly_median_r_str = f"{yearly_median_r:.3f}" if not np.isnan(yearly_median_r) else "NaN"

            report_lines.append(f"\nğŸ“… å¹´åº¦äº¤å‰éªŒè¯ (æ—¶é—´è¯„ä¼°):")
            report_lines.append(f"  â”Œ{'â”€' * 20}â”¬{'â”€' * 10}â”¬{'â”€' * 10}â”¬{'â”€' * 10}â”")
            report_lines.append(f"  â”‚ {'æŒ‡æ ‡':18} â”‚ {'èšåˆ':8} â”‚ {'å¹³å‡':8} â”‚ {'ä¸­ä½æ•°':8} â”‚")
            report_lines.append(f"  â”œ{'â”€' * 20}â”¼{'â”€' * 10}â”¼{'â”€' * 10}â”¼{'â”€' * 10}â”¤")
            report_lines.append(
                f"  â”‚ {'MAE (mm)':18} â”‚ {yearly_overall['MAE']:8.3f} â”‚ {yearly_mean['MAE']:8.3f} â”‚ {yearly_median['MAE']:8.3f} â”‚")
            report_lines.append(
                f"  â”‚ {'RMSE (mm)':18} â”‚ {yearly_overall['RMSE']:8.3f} â”‚ {yearly_mean['RMSE']:8.3f} â”‚ {yearly_median['RMSE']:8.3f} â”‚")
            report_lines.append(
                f"  â”‚ {'R':18} â”‚ {yearly_overall_r_str:>8} â”‚ {yearly_mean_r_str:>8} â”‚ {yearly_median_r_str:>8} â”‚")
            report_lines.append(f"  â””{'â”€' * 20}â”´{'â”€' * 10}â”´{'â”€' * 10}â”´{'â”€' * 10}â”˜")

            report_lines.append(f"  æŠ˜å æ•°: {results['yearly_cv']['folds']}")
            report_lines.append(f"  æ ·æœ¬æ•°: {yearly_overall['æ ·æœ¬æ•°']}")
            report_lines.append(
                f"  å„æŠ˜å æ ‡å‡†å·®: MAEÂ±{yearly_std['MAE']:.3f}, RMSEÂ±{yearly_std['RMSE']:.3f}, RÂ±{yearly_std['R']:.3f}")

        # æ¨¡å‹å‚æ•°
        report_lines.append(f"\nâš™ï¸ æ¨¡å‹å‚æ•°:")
        for key, value in self.params.items():
            if key in ['n_estimators', 'max_depth', 'min_child_weight']:
                report_lines.append(f"  {key}: {value}")
            elif key in ['learning_rate', 'subsample', 'colsample_bytree', 'reg_alpha', 'gamma']:
                report_lines.append(f"  {key}: {value}")

        # ç‰¹å¾é‡è¦æ€§
        if 'feature_importance' in results:
            top_features = results['feature_importance'].head(5)
            report_lines.append(f"\nğŸ” å‰5ä¸ªé‡è¦ç‰¹å¾:")
            for i, (_, row) in enumerate(top_features.iterrows(), 1):
                report_lines.append(f"  {i}. {row['feature']}: {row['importance']:.4f}")

        # æ€§èƒ½æ¯”è¾ƒå’Œå»ºè®®
        if 'station_cv' in results and 'yearly_cv' in results:
            # ä½¿ç”¨èšåˆå€¼è¿›è¡Œæ¯”è¾ƒ
            station_r = results['station_cv']['overall']['R']
            yearly_r = results['yearly_cv']['overall']['R']

            # åªæœ‰å½“ä¸¤ä¸ªRå€¼éƒ½ä¸æ˜¯NaNæ—¶æ‰è¿›è¡Œæ¯”è¾ƒ
            if not np.isnan(station_r) and not np.isnan(yearly_r):
                report_lines.append(f"\nğŸ’¡ æ€§èƒ½åˆ†æå’Œå»ºè®®:")
                report_lines.append(f"  â€¢ èšåˆæ€§èƒ½æ¯”è¾ƒ:")
                if station_r > yearly_r:
                    report_lines.append(f"    ç«™ç‚¹CVä¼˜äºå¹´åº¦CV (R: {station_r:.3f} > {yearly_r:.3f})")
                else:
                    report_lines.append(f"    å¹´åº¦CVä¼˜äºç«™ç‚¹CV (R: {yearly_r:.3f} > {station_r:.3f})")
            else:
                report_lines.append(f"\nğŸ’¡ æ€§èƒ½åˆ†æ:")
                if np.isnan(station_r) and np.isnan(yearly_r):
                    report_lines.append(f"  â€¢ ä¸¤ç§æ–¹æ³•çš„ç›¸å…³ç³»æ•°å‡ä¸ºNaNï¼Œæ— æ³•æ¯”è¾ƒRå€¼")
                elif np.isnan(station_r):
                    report_lines.append(f"  â€¢ ç«™ç‚¹CVç›¸å…³ç³»æ•°ä¸ºNaNï¼Œå¹´åº¦CV R={yearly_r:.3f}")
                else:
                    report_lines.append(f"  â€¢ å¹´åº¦CVç›¸å…³ç³»æ•°ä¸ºNaNï¼Œç«™ç‚¹CV R={station_r:.3f}")

            # æ¯”è¾ƒç¨³å®šæ€§ï¼ˆæ ‡å‡†å·®è¶Šå°è¶Šç¨³å®šï¼‰
            station_mae_std = results['station_cv']['std']['MAE']
            yearly_mae_std = results['yearly_cv']['std']['MAE']

            if station_mae_std < yearly_mae_std:
                report_lines.append(f"  â€¢ ç¨³å®šæ€§æ¯”è¾ƒ: ç«™ç‚¹CVæ›´ç¨³å®š (MAEæ ‡å‡†å·®: {station_mae_std:.3f} < {yearly_mae_std:.3f})")
            else:
                report_lines.append(f"  â€¢ ç¨³å®šæ€§æ¯”è¾ƒ: å¹´åº¦CVæ›´ç¨³å®š (MAEæ ‡å‡†å·®: {yearly_mae_std:.3f} < {station_mae_std:.3f})")

            # æœ€ç»ˆå»ºè®®
            if station_r > yearly_r and station_mae_std < yearly_mae_std:
                report_lines.append(f"  âœ… å¼ºçƒˆæ¨èä½¿ç”¨ç«™ç‚¹äº¤å‰éªŒè¯è¿›è¡Œç©ºé—´è¯„ä¼°")
            elif yearly_r > station_r and yearly_mae_std < station_mae_std:
                report_lines.append(f"  âœ… å¼ºçƒˆæ¨èä½¿ç”¨å¹´åº¦äº¤å‰éªŒè¯è¿›è¡Œæ—¶é—´è¯„ä¼°")
            else:
                report_lines.append(f"  âš ï¸  ä¸¤ç§æ–¹æ³•å„æœ‰ä¼˜åŠ¿ï¼Œè¯·æ ¹æ®å…·ä½“åº”ç”¨åœºæ™¯é€‰æ‹©")

        report_lines.append("\n" + "=" * 80)

        return "\n".join(report_lines)

    # ä¾¿æ·ä½¿ç”¨å‡½æ•°


def train_swe_model(data_df, output_dir=None, params=None):
    """ä¾¿æ·å‡½æ•°ï¼šè®­ç»ƒSWEæ¨¡å‹

        Args:
            data_df (pd.DataFrame): åŒ…å«ç‰¹å¾å’ŒSWEçš„æ•°æ®
            output_dir (str, optional): è¾“å‡ºç›®å½•è·¯å¾„
            params (dict, optional): XGBoostå‚æ•°

        Returns:
            dict: åŒ…å«æ‰€æœ‰è®­ç»ƒç»“æœçš„å­—å…¸

        Example:
            >>> results = train_swe_model(df, output_dir='./results')
            >>> print(f"ç«™ç‚¹CV R: {results['station_cv']['overall']['R']:.3f}")
        """
    trainer = SWEXGBoostTrainer(params=params)
    return trainer.run_complete_analysis(data_df, output_dir)
