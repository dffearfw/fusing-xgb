import json
import pandas as pd
import os
from optuna_optimizer import optimize_swe_model


def find_data_file(filename):
    """æŸ¥æ‰¾æ•°æ®æ–‡ä»¶"""
    search_paths = [
        filename,
        os.path.join(os.path.dirname(__file__), filename),
        os.path.join(os.path.dirname(os.path.dirname(__file__)), filename),
        os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'data', filename),
        os.path.join('/data/', filename),
    ]

    for path in search_paths:
        if os.path.exists(path):
            print(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {path}")
            return path

    print("âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼Œå°è¯•çš„è·¯å¾„:")
    for path in search_paths:
        print(f"  {path}")
    return None


def load_data(file_path):
    """åŠ è½½æ•°æ®æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œç¼–ç """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    file_ext = os.path.splitext(file_path)[1].lower()

    try:
        if file_ext == '.csv':
            # å°è¯•å¤šç§ç¼–ç 
            encodings = ['utf-8', 'gbk', 'latin1', 'cp936']
            for encoding in encodings:
                try:
                    df = pd.read_csv(file_path, encoding=encoding)
                    print(f"âœ… ä½¿ç”¨ {encoding} ç¼–ç æˆåŠŸåŠ è½½CSVæ–‡ä»¶: {len(df)} è¡Œ")
                    return df
                except UnicodeDecodeError:
                    continue
            raise ValueError(f"æ— æ³•ç”¨ä»»ä½•ç¼–ç åŠ è½½CSVæ–‡ä»¶: {file_path}")

        elif file_ext in ['.xlsx', '.xls']:
            df = pd.read_excel(file_path)
            print(f"âœ… æˆåŠŸåŠ è½½Excelæ–‡ä»¶: {len(df)} è¡Œ")
            return df

        elif file_ext == '.parquet':
            df = pd.read_parquet(file_path)
            print(f"âœ… æˆåŠŸåŠ è½½Parquetæ–‡ä»¶: {len(df)} è¡Œ")
            return df

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        raise


def run_optimized_training(data_path=None):
    """è¿è¡Œä¼˜åŒ–åŽçš„è®­ç»ƒ"""

    # å¦‚æžœæ²¡æœ‰æä¾›è·¯å¾„ï¼Œå°è¯•è‡ªåŠ¨æŸ¥æ‰¾
    if data_path is None:
        possible_files = ['lu_onehot.xlsx', 'data.csv', 'swe_data.csv']
        for filename in possible_files:
            data_path = find_data_file(filename)
            if data_path:
                break
        else:
            print("âŒ è¯·æä¾›æ•°æ®æ–‡ä»¶è·¯å¾„")
            return

    # åŠ è½½æ•°æ®
    print(f"ðŸ“¥ åŠ è½½æ•°æ®: {data_path}")
    df = load_data(data_path)

    print(f"ðŸ“Š æ•°æ®æ¦‚å†µ: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
    print(f"ðŸ“‹ æ•°æ®åˆ—: {list(df.columns)}")

    # æ£€æŸ¥å¿…è¦åˆ—
    required_cols = ['swe', 'station_id', 'date']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"âš ï¸  ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        print("ðŸ’¡ å¯ç”¨åˆ—:", list(df.columns))
        return

    print("ðŸš€ å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–...")

    try:
        # ä¼˜åŒ–RFå‚æ•°
        print("\nðŸ”§ ä¼˜åŒ–éšæœºæ£®æž—å‚æ•°...")
        rf_params = optimize_swe_model(df, 'rf', n_trials=30)  # å‡å°‘è¯•éªŒæ¬¡æ•°åŠ é€Ÿ

        # ä¼˜åŒ–XGBoostå‚æ•°
        print("\nðŸ”§ ä¼˜åŒ–XGBoostå‚æ•°...")
        xgb_params = optimize_swe_model(df, 'xgb', n_trials=30)

        # ä¼˜åŒ–GNNWRå‚æ•°ï¼ˆè€—æ—¶è¾ƒé•¿ï¼Œå‡å°‘è¯•éªŒæ¬¡æ•°ï¼‰
        print("\nðŸ”§ ä¼˜åŒ–GNNWRå‚æ•°...")
        gnnwr_params = optimize_swe_model(df, 'gnnwr', n_trials=10)

        # ä¿å­˜ä¼˜åŒ–ç»“æžœ
        optimized_params = {
            'rf': rf_params,
            'xgb': xgb_params,
            'gnnwr': gnnwr_params
        }

        with open('optimized_params.json', 'w', encoding='utf-8') as f:
            json.dump(optimized_params, f, indent=2, ensure_ascii=False)

        print("\nâœ… è¶…å‚æ•°ä¼˜åŒ–å®Œæˆï¼")
        print("ðŸ“Š ä¼˜åŒ–ç»“æžœå·²ä¿å­˜åˆ° optimized_params.json")

        # æ˜¾ç¤ºä¼˜åŒ–ç»“æžœ
        for model_type, params in optimized_params.items():
            print(f"\n{model_type.upper()} æœ€ä½³å‚æ•°:")
            for key, value in params.items():
                print(f"  {key}: {value}")

        return optimized_params

    except Exception as e:
        print(f"âŒ ä¼˜åŒ–è¿‡ç¨‹å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None


if __name__ == "__main__":
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    import sys

    if len(sys.argv) > 1:
        data_path = sys.argv[1]
    else:
        data_path = None

    run_optimized_training(data_path)