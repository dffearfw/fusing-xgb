import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from gnnw_xgboost_trainer import GNNW_XGBoostTrainer


def verify_weight_application(df, n_samples=100):
    """ä¸¥æ ¼éªŒè¯æƒé‡æ˜¯å¦è¢«æ­£ç¡®åº”ç”¨åˆ°ç‰¹å¾ä¸Š"""
    print("=" * 80)
    print("ğŸ§ª GNNW-XGBoostæƒé‡åº”ç”¨éªŒè¯æµ‹è¯•")
    print("=" * 80)

    # åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
    trainer = GNNW_XGBoostTrainer(use_gnnwr=True)

    # é¢„å¤„ç†æ•°æ®
    print("\n1. æ•°æ®é¢„å¤„ç†...")
    X, y, station_groups, year_groups, gnnwr_data = trainer.preprocess_data(df)

    print(f"  åŸå§‹æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
    print(f"  GNNWRæ•°æ®å½¢çŠ¶: {gnnwr_data.shape}")
    print(f"  ç‰¹å¾åˆ—æ•°: {len(trainer.feature_columns)}")
    print(f"  GNNWRç‰¹å¾åˆ—: {len(trainer.gnnwr_x_columns)}")

    # åªå–å‰n_samplesä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
    X_test = X[:n_samples]
    y_test = y[:n_samples]
    gnnwr_data_test = gnnwr_data.iloc[:n_samples].copy()

    print(f"\n2. æµ‹è¯•æ ·æœ¬: ä½¿ç”¨å‰{n_samples}ä¸ªæ ·æœ¬")

    # è·å–æƒé‡çŸ©é˜µï¼ˆç”¨å…¨éƒ¨æ ·æœ¬ä½œä¸ºè®­ç»ƒé›†ï¼Œè‡ªå·±ä½œä¸ºéªŒè¯é›†æ¥è·å¾—æƒé‡ï¼‰
    print("\n3. è·å–æƒé‡çŸ©é˜µ...")
    train_weights, val_weights = trainer._train_gnnwr_for_fold_debug(gnnwr_data_test, gnnwr_data_test.head(1))

    if train_weights is None:
        print("âŒ æ— æ³•è·å–æƒé‡çŸ©é˜µ")
        return

    print(f"\n4. æƒé‡çŸ©é˜µåˆ†æ:")
    print(f"   å½¢çŠ¶: {train_weights.shape}")
    print(f"   å‡å€¼: {train_weights.mean():.6f}")
    print(f"   æ ‡å‡†å·®: {train_weights.std():.6f}")
    print(f"   èŒƒå›´: [{train_weights.min():.6f}, {train_weights.max():.6f}]")
    print(f"   è´Ÿæƒé‡æ¯”ä¾‹: {(train_weights < 0).mean():.2%}")

    # æ£€æŸ¥æƒé‡æ˜¯å¦æ˜¾è‘—ä¸åŒäº1ï¼ˆå¦‚æœæ˜¯1ï¼Œä¹˜ä»¥æƒé‡å°±æ²¡å˜åŒ–ï¼‰
    weight_distance_from_one = np.abs(train_weights - 1).mean()
    print(f"   æƒé‡ä¸1çš„å¹³å‡è·ç¦»: {weight_distance_from_one:.6f}")

    if weight_distance_from_one < 0.01:
        print("   âš ï¸ è­¦å‘Š: æƒé‡éå¸¸æ¥è¿‘1ï¼ŒåŠ æƒå¯èƒ½æ²¡æœ‰æ•ˆæœ")
    else:
        print(f"   âœ… æƒé‡ä¸1æœ‰æ˜¾è‘—å·®å¼‚ï¼ŒåŠ æƒä¼šæœ‰æ•ˆæœ")

    # 5. åº”ç”¨æƒé‡
    print("\n5. åº”ç”¨æƒé‡åˆ°ç‰¹å¾...")

    # åŸå§‹ç‰¹å¾
    original_features = X_test.copy()

    # åº”ç”¨æƒé‡
    weighted_features = trainer._apply_gnnwr_weights_with_debug(
        original_features, train_weights,
        trainer.feature_columns, trainer.gnnwr_x_columns
    )

    # 6. è¯¦ç»†å¯¹æ¯”åŸå§‹ç‰¹å¾å’ŒåŠ æƒç‰¹å¾
    print("\n6. ç‰¹å¾å˜åŒ–åˆ†æ:")

    # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å˜åŒ–
    changes = weighted_features - original_features
    abs_changes = np.abs(changes)
    relative_changes = abs_changes / (np.abs(original_features) + 1e-10)  # é¿å…é™¤ä»¥0

    # æŒ‰ç‰¹å¾ç»Ÿè®¡å˜åŒ–
    feature_changes = []
    for i in range(original_features.shape[1]):
        feat_name = trainer.feature_columns[i] if i < len(trainer.feature_columns) else f"Feature_{i}"

        # æ£€æŸ¥è¿™ä¸ªç‰¹å¾æ˜¯å¦åœ¨GNNWRç‰¹å¾ä¸­
        is_gnnwr_feature = feat_name in trainer.gnnwr_x_columns

        # ç»Ÿè®¡å˜åŒ–
        if is_gnnwr_feature:
            feat_change_mean = changes[:, i].mean()
            feat_change_std = changes[:, i].std()
            feat_abs_change_mean = abs_changes[:, i].mean()
            feat_rel_change_mean = relative_changes[:, i].mean()

            feature_changes.append({
                'feature': feat_name,
                'is_gnnwr': is_gnnwr_feature,
                'change_mean': feat_change_mean,
                'change_std': feat_change_std,
                'abs_change_mean': feat_abs_change_mean,
                'rel_change_mean': feat_rel_change_mean
            })

    # åˆ›å»ºDataFrameæ˜¾ç¤ºç»“æœ
    changes_df = pd.DataFrame(feature_changes)

    print("\n  GNNWRç‰¹å¾çš„å˜åŒ–ç»Ÿè®¡:")
    print("  " + "-" * 100)

    # æŒ‰ç»å¯¹å˜åŒ–æ’åº
    sorted_changes = changes_df.sort_values('abs_change_mean', ascending=False)

    for idx, row in sorted_changes.head(10).iterrows():
        print(f"    {row['feature']:<30} å¹³å‡å˜åŒ–: {row['change_mean']:+.6f} (Â±{row['change_std']:.6f}), "
              f"ç»å¯¹å˜åŒ–: {row['abs_change_mean']:.6f}, ç›¸å¯¹å˜åŒ–: {row['rel_change_mean']:.2%}")

    # 7. å¯è§†åŒ–å˜åŒ–
    print("\n7. å¯è§†åŒ–ç‰¹å¾å˜åŒ–...")
    visualize_feature_changes(original_features, weighted_features, changes_df, n_top=10)

    # 8. ç»Ÿè®¡æ€»ç»“
    print("\n8. éªŒè¯ç»“æœæ€»ç»“:")

    total_features = original_features.shape[1]
    gnnwr_features_count = sum([1 for f in trainer.feature_columns if f in trainer.gnnwr_x_columns])
    non_gnnwr_features_count = total_features - gnnwr_features_count

    print(f"   æ€»ç‰¹å¾æ•°: {total_features}")
    print(f"   GNNWRç‰¹å¾æ•°: {gnnwr_features_count} (ä¼šåŠ æƒ)")
    print(f"   éGNNWRç‰¹å¾æ•°: {non_gnnwr_features_count} (ä¿æŒä¸å˜)")

    # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å¾ç¡®å®è¢«åŠ æƒäº†
    mean_abs_change = abs_changes.mean()
    significant_changes = (abs_changes > 1e-6).sum() / abs_changes.size

    print(f"\n   ç‰¹å¾å¹³å‡ç»å¯¹å˜åŒ–: {mean_abs_change:.6f}")
    print(f"   æœ‰æ˜¾è‘—å˜åŒ–(>1e-6)çš„æ¯”ä¾‹: {significant_changes:.2%}")

    if mean_abs_change > 0.001 and significant_changes > 0.1:
        print(f"\n   âœ… éªŒè¯é€šè¿‡: æƒé‡å·²æˆåŠŸåº”ç”¨åˆ°ç‰¹å¾ä¸Š")
        print(f"      å¹³å‡å˜åŒ–: {mean_abs_change:.6f}")
        print(f"      æ˜¾è‘—å˜åŒ–æ¯”ä¾‹: {significant_changes:.2%}")
    else:
        print(f"\n   âŒ éªŒè¯å¤±è´¥: ç‰¹å¾å˜åŒ–å¤ªå°æˆ–æ²¡æœ‰å˜åŒ–")
        print(f"      è¯·æ£€æŸ¥æƒé‡çŸ©é˜µå’Œç‰¹å¾å¯¹é½")

    return {
        'original_features': original_features,
        'weighted_features': weighted_features,
        'weights': train_weights,
        'feature_changes': changes_df,
        'summary': {
            'mean_abs_change': mean_abs_change,
            'significant_changes': significant_changes,
            'gnnwr_features_count': gnnwr_features_count,
            'total_features': total_features
        }
    }


def visualize_feature_changes(original, weighted, changes_df, n_top=10):
    """å¯è§†åŒ–ç‰¹å¾å˜åŒ–"""

    # é€‰æ‹©å˜åŒ–æœ€å¤§çš„ç‰¹å¾
    top_features = changes_df.nlargest(min(n_top, len(changes_df)), 'abs_change_mean')

    fig, axes = plt.subplots(2, min(3, len(top_features)), figsize=(15, 8))
    axes = axes.flatten()

    for idx, (_, row) in enumerate(top_features.iterrows()):
        if idx >= len(axes):
            break

        # æ‰¾åˆ°ç‰¹å¾ç´¢å¼•
        feat_name = row['feature']
        feat_idx = list(changes_df['feature']).index(feat_name)

        ax = axes[idx]

        # åŸå§‹ç‰¹å¾å’ŒåŠ æƒç‰¹å¾
        ax.scatter(original[:, feat_idx], weighted[:, feat_idx], alpha=0.6, s=20)

        # å¯¹è§’çº¿ï¼ˆy=xçº¿ï¼‰
        min_val = min(original[:, feat_idx].min(), weighted[:, feat_idx].min())
        max_val = max(original[:, feat_idx].max(), weighted[:, feat_idx].max())
        ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5)

        ax.set_xlabel(f'åŸå§‹ {feat_name}')
        ax.set_ylabel(f'åŠ æƒ {feat_name}')
        ax.set_title(f'{feat_name}\nå˜åŒ–: {row["abs_change_mean"]:.4f}')
        ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('weight_application_verification.png', dpi=150, bbox_inches='tight')
    plt.show()

    # åˆ›å»ºæƒé‡åˆ†å¸ƒå›¾
    plt.figure(figsize=(10, 6))

    # æå–æ‰€æœ‰æƒé‡å€¼
    all_weights = []
    for idx, row in changes_df.iterrows():
        feat_idx = list(changes_df['feature']).index(row['feature'])
        all_weights.extend(row['abs_change_mean'])

    # ç»˜åˆ¶æƒé‡åˆ†å¸ƒ
    plt.hist(all_weights, bins=30, alpha=0.7, edgecolor='black')
    plt.xlabel('ç‰¹å¾å˜åŒ–ç»å¯¹å€¼')
    plt.ylabel('é¢‘æ•°')
    plt.title('GNNWRæƒé‡åº”ç”¨åç‰¹å¾å˜åŒ–åˆ†å¸ƒ')
    plt.grid(True, alpha=0.3)
    plt.savefig('feature_changes_distribution.png', dpi=150, bbox_inches='tight')
    plt.show()


# åœ¨GNNW_XGBoostTrainerç±»ä¸­æ·»åŠ è°ƒè¯•æ–¹æ³•
def _apply_gnnwr_weights_with_debug(self, X, weights, feature_columns, gnnwr_x_columns):
    """å¸¦è°ƒè¯•ä¿¡æ¯çš„æƒé‡åº”ç”¨"""
    if weights is None:
        print("âŒ æƒé‡çŸ©é˜µä¸ºNone")
        return X

    print(f"\nğŸ”§ æƒé‡åº”ç”¨è¯¦ç»†ä¿¡æ¯:")
    print(f"  è¾“å…¥Xå½¢çŠ¶: {X.shape}")
    print(f"  æƒé‡çŸ©é˜µå½¢çŠ¶: {weights.shape}")
    print(f"  XGBoostç‰¹å¾æ•°: {len(feature_columns)}")
    print(f"  GNNWRç‰¹å¾æ•°: {len(gnnwr_x_columns)}")

    # åˆ›å»ºç‰¹å¾æ˜ å°„
    feature_to_gnnwr = {}
    feature_map_info = []

    for i, feat in enumerate(feature_columns):
        if feat in gnnwr_x_columns:
            gnnwr_idx = gnnwr_x_columns.index(feat)
            feature_to_gnnwr[i] = gnnwr_idx
            feature_map_info.append(f"{feat} (XGB idx:{i} -> GNNWR idx:{gnnwr_idx})")

    print(f"\n  ç‰¹å¾æ˜ å°„ ({len(feature_to_gnnwr)}ä¸ªåŒ¹é…ç‰¹å¾):")
    for info in feature_map_info[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
        print(f"    {info}")

    if len(feature_map_info) > 10:
        print(f"    ... è¿˜æœ‰{len(feature_map_info) - 10}ä¸ªç‰¹å¾")

    # åº”ç”¨æƒé‡
    X_weighted = X.copy()
    total_change = 0

    for feat_idx, gnnwr_idx in feature_to_gnnwr.items():
        if gnnwr_idx < weights.shape[1]:
            original_values = X[:, feat_idx]
            weight_values = weights[:, gnnwr_idx]
            weighted_values = original_values * weight_values

            # è®¡ç®—å˜åŒ–
            change = np.abs(weighted_values - original_values).mean()
            total_change += change

            # å¦‚æœå˜åŒ–æ˜¾è‘—ï¼Œæ‰“å°è¯¦ç»†ä¿¡æ¯
            if change > 0.01:  # å˜åŒ–å¤§äº0.01
                print(f"\n   æ˜¾è‘—å˜åŒ–ç‰¹å¾: {feature_columns[feat_idx]}")
                print(f"     åŸå§‹å€¼èŒƒå›´: [{original_values.min():.3f}, {original_values.max():.3f}]")
                print(f"     æƒé‡å€¼èŒƒå›´: [{weight_values.min():.3f}, {weight_values.max():.3f}]")
                print(f"     åŠ æƒå€¼èŒƒå›´: [{weighted_values.min():.3f}, {weighted_values.max():.3f}]")
                print(f"     å¹³å‡ç»å¯¹å˜åŒ–: {change:.6f}")

            X_weighted[:, feat_idx] = weighted_values

    print(f"\n  æ€»å¹³å‡å˜åŒ–: {total_change / len(feature_to_gnnwr):.6f}")
    return X_weighted


def _train_gnnwr_for_fold_debug(self, train_data, val_data):
    """å¸¦è°ƒè¯•ä¿¡æ¯çš„GNNWRè®­ç»ƒ"""
    print("ğŸ”¬ GNNWRè®­ç»ƒè°ƒè¯•æ¨¡å¼...")
    print(f"  è®­ç»ƒæ•°æ®å½¢çŠ¶: {train_data.shape}")
    print(f"  éªŒè¯æ•°æ®å½¢çŠ¶: {val_data.shape}")

    # è°ƒç”¨åŸå§‹æ–¹æ³•
    train_weights, val_weights = self._train_gnnwr_for_fold(train_data, val_data)

    if train_weights is not None:
        print(f"  è®­ç»ƒæƒé‡çŸ©é˜µç»Ÿè®¡:")
        print(f"    å½¢çŠ¶: {train_weights.shape}")
        print(f"    å‡å€¼: {train_weights.mean():.6f}")
        print(f"    æ ‡å‡†å·®: {train_weights.std():.6f}")
        print(f"    æœ€å°æƒé‡: {train_weights.min():.6f}")
        print(f"    æœ€å¤§æƒé‡: {train_weights.max():.6f}")

        # æ£€æŸ¥æƒé‡åˆ†å¸ƒ
        unique_weights = np.unique(train_weights)
        print(f"    å”¯ä¸€æƒé‡å€¼æ•°é‡: {len(unique_weights)}")

        # å¦‚æœæƒé‡å¤ªå•ä¸€ï¼Œå¯èƒ½æœ‰é”™è¯¯
        if len(unique_weights) < 10:
            print(f"    æƒé‡å€¼: {unique_weights[:10]}")

    return train_weights, val_weights


# å°†è°ƒè¯•æ–¹æ³•æ·»åŠ åˆ°ç±»ä¸­
GNNW_XGBoostTrainer._apply_gnnwr_weights_with_debug = _apply_gnnwr_weights_with_debug
GNNW_XGBoostTrainer._train_gnnwr_for_fold_debug = _train_gnnwr_for_fold_debug


# ä¸»éªŒè¯å‡½æ•°
def main_verification():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("å¼€å§‹GNNW-XGBoostæƒé‡åº”ç”¨éªŒè¯...")

    # åŠ è½½æ•°æ®
    df = pd.read_excel('aggregated_station_data.xlsx')

    # è¿è¡ŒéªŒè¯
    results = verify_weight_application(df, n_samples=100)

    if results:
        print("\n" + "=" * 80)
        print("âœ… éªŒè¯å®Œæˆï¼")

        summary = results['summary']
        if summary['mean_abs_change'] > 0.001 and summary['significant_changes'] > 0.1:
            print("ğŸ¯ ç»“è®º: æƒé‡å·²æˆåŠŸåº”ç”¨åˆ°ç‰¹å¾ä¸Š")
            print(f"   å¹³å‡ç‰¹å¾å˜åŒ–: {summary['mean_abs_change']:.6f}")
            print(f"   æ˜¾è‘—å˜åŒ–æ¯”ä¾‹: {summary['significant_changes']:.2%}")
            print(f"   {summary['gnnwr_features_count']}/{summary['total_features']}ä¸ªç‰¹å¾è¢«åŠ æƒ")
        else:
            print("âš ï¸  è­¦å‘Š: ç‰¹å¾å˜åŒ–å¤ªå°")
            print("   å¯èƒ½çš„åŸå› :")
            print("   1. GNNWRæ²¡æœ‰å­¦åˆ°æœ‰æ•ˆçš„æƒé‡")
            print("   2. æƒé‡å€¼æ¥è¿‘1.0")
            print("   3. ç‰¹å¾å’Œæƒé‡æ²¡æœ‰æ­£ç¡®å¯¹é½")
            print("   4. GNNWRè®­ç»ƒè½®æ•°å¤ªå°‘")

        # ä¿å­˜éªŒè¯ç»“æœ
        pd.DataFrame(results['feature_changes']).to_csv('feature_changes_analysis.csv', index=False)

        print("\nğŸ“ éªŒè¯ç»“æœå·²ä¿å­˜:")
        print("   - weight_application_verification.png (å¯è§†åŒ–)")
        print("   - feature_changes_distribution.png (åˆ†å¸ƒå›¾)")
        print("   - feature_changes_analysis.csv (è¯¦ç»†æ•°æ®)")

    return results


if __name__ == "__main__":
    main_verification()